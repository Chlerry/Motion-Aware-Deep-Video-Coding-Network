{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Disable INFO and WARNING messages from TensorFlow\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import numpy as np\n",
    "from imp import reload\n",
    "from keras.layers import * # YL\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# ============== DL ===============================\n",
    "# Limit GPU memory(VRAM) usage in TensorFlow 2.0\n",
    "# https://github.com/tensorflow/tensorflow/issues/34355\n",
    "# https://medium.com/@starriet87/tensorflow-2-0-wanna-limit-gpu-memory-10ad474e2528\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# ---- Method 1 ----\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "# ============== DL ===============================\n",
    "from utility.helper import psnr, load_imgs, image_to_block, regroup, save_imgs, performance_evaluation\n",
    "from utility.parameter import *\n",
    "\n",
    "import coarse.train as coarse_train\n",
    "import coarse.test as coarse_test\n",
    "import prediction.b1_train as prediction_train_b1\n",
    "import prediction.b1_inference as prediction_inference_b1\n",
    "import prediction.b23_train as prediction_train_b23\n",
    "import prediction.b23_inference as prediction_inference_b23\n",
    "import residue.b1_train as residue_train_b1\n",
    "import residue.b_inference as residue_final\n",
    "\n",
    "# ============== DL ===============================\n",
    "# Default is 1e-7 which is too small for float16.  \n",
    "# Without adjusting the epsilon, we will get NaN predictions because of divide by zero problems\n",
    "import keras.backend as K\n",
    "if rtx_optimizer == True:\n",
    "    K.set_epsilon(1e-4) \n",
    "# =================================================\n",
    "\n",
    "b = 16 # blk_size\n",
    "bm = 8 # target block size to predict\n",
    "\n",
    "train_start, train_end = 0, 100\n",
    "train_images = load_imgs(data_dir, train_start, train_end) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==== coarse train b1 ====\n",
    "coarse_train.model(train_images, b, training_ratio)\n",
    "\n",
    "# ==== prediction train b1 ====\n",
    "decoded = coarse_test.predict(train_images, b, training_ratio)\n",
    "prediction_train_b1.pred_train(train_images, train_images, b, bm, training_ratio)\n",
    "\n",
    "# ==== residue train b1 ====\n",
    "predicted_b1_frame = prediction_inference_b1.pred_inference_b1(decoded, b, bm, training_ratio)\n",
    "residue = train_images[2:-2] - predicted_b1_frame\n",
    "residue_train_b1.residue_train(residue, b, training_ratio, \"residue_b1\")\n",
    "\n",
    "# ==== prediction train b23 ====\n",
    "final_predicted_b1 = residue_final.residue_inference(train_images[2:-2], predicted_b1_frame, b, training_ratio, \"residue_b1\")\n",
    "prediction_train_b23.pred_train_b23(decoded[:-4], final_predicted_b1, train_images[1:-3], b, bm, training_ratio)\n",
    "\n",
    "# ==== residue train b23 ====\n",
    "predicted_b2_frame = prediction_inference_b23.pred_inference_b23( \\\n",
    "        decoded[:-4], final_predicted_b1, b, bm, training_ratio)\n",
    "residue = train_images[1:-3] - predicted_b2_frame\n",
    "residue_train_b1.residue_train(residue, b, training_ratio, \"residue_b23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from C:/Users/danni/Documents/GitHub/SPIEcode-Daniel/models/BlowingBubbles_416x240_50/6/hdf5/coarse.hdf5\n",
      "n_evaluated: 100\n",
      "average test coarse_amse: 38.80278375400641\n",
      "average test coarse_apsnr: 32.25159561142316\n",
      "average test coarse_assim: 0.8599097406034266\n"
     ]
    }
   ],
   "source": [
    "# ---- coarse ----\n",
    "test_images = load_imgs(data_dir, test_start, test_end)\n",
    "decoded = coarse_test.predict(test_images, b, testing_ratio)\n",
    "\n",
    "n2_evaluated, coarse_amse, coarse_apsnr, coarse_assim = performance_evaluation(test_images, decoded, 0, 1)\n",
    "print('n_evaluated:',n2_evaluated)\n",
    "print('average test coarse_amse:',coarse_amse)\n",
    "print('average test coarse_apsnr:',coarse_apsnr)\n",
    "print('average test coarse_assim:',coarse_assim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from C:/Users/danni/Documents/GitHub/SPIEcode-Daniel/models/BlowingBubbles_416x240_50/6/hdf5/prediction.hdf5\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "n_b1: 24\n",
      "average test b1_amse: 52.26640249399039\n",
      "average test b1_apsnr: 30.968839219179713\n",
      "average test b1_assim: 0.771172010062665\n"
     ]
    }
   ],
   "source": [
    "# ---- prediction b1 ----\n",
    "predicted_b1_frame = prediction_inference_b1.pred_inference_b1(decoded, b, bm, testing_ratio, \"prediction\")\n",
    "\n",
    "n_predicted1, amse1, apsnr1, assim1 = performance_evaluation(test_images[2:-2], predicted_b1_frame, 0, 4)\n",
    "print(\"vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\")\n",
    "print('n_b1:',n_predicted1)\n",
    "print('average test b1_amse:',amse1)\n",
    "print('average test b1_apsnr:',apsnr1)\n",
    "print('average test b1_assim:',assim1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from C:/Users/danni/Documents/GitHub/SPIEcode-Daniel/models/BlowingBubbles_416x240_50/6/hdf5/residue_b1.hdf5\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "n_b1: 24\n",
      "average test b1_amse: 41.511045728721506\n",
      "average test b1_apsnr: 31.970928090276107\n",
      "average test b1_assim: 0.8323878612398107\n"
     ]
    }
   ],
   "source": [
    "# ---- residue b1 ----\n",
    "final_predicted_b1 = residue_final.residue_inference( \\\n",
    "    test_images[2:-2], predicted_b1_frame, b, testing_ratio, \"residue_b1\")\n",
    "\n",
    "n_predicted1, amse1, apsnr1, assim1 = performance_evaluation(test_images[2:-2], final_predicted_b1, 0, 4)\n",
    "print(\"vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\")\n",
    "print('n_b1:',n_predicted1)\n",
    "print('average test b1_amse:',amse1)\n",
    "print('average test b1_apsnr:',apsnr1)\n",
    "print('average test b1_assim:',assim1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from C:/Users/danni/Documents/GitHub/SPIEcode-Daniel/models/BlowingBubbles_416x240_50/6/hdf5/prediction.hdf5\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "n_b2: 24\n",
      "average test b2_amse: 52.25093900240385\n",
      "average test b2_apsnr: 30.962931402834233\n",
      "average test b2_assim: 0.7815542706916371\n"
     ]
    }
   ],
   "source": [
    "# ---- prediction b23 ----\n",
    "predicted_b2_frame = prediction_inference_b23.pred_inference_b23( \\\n",
    "    decoded[:-4], final_predicted_b1, b, bm, testing_ratio, \"prediction\")\n",
    "\n",
    "n_predicted2, amse2, apsnr2, assim2 = performance_evaluation(test_images[1:-3], predicted_b2_frame, 0, 4)\n",
    "print(\"vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\")\n",
    "print('n_b2:',n_predicted2)\n",
    "print('average test b2_amse:',amse2)\n",
    "print('average test b2_apsnr:',apsnr2)\n",
    "print('average test b2_assim:',assim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from C:/Users/danni/Documents/GitHub/SPIEcode-Daniel/models/BlowingBubbles_416x240_50/6/hdf5/residue_b1.hdf5\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "n_b2: 24\n",
      "average test b2_amse: 43.1427144542379\n",
      "average test b2_apsnr: 31.79487929845393\n",
      "average test b2_assim: 0.8309672192313989\n"
     ]
    }
   ],
   "source": [
    "# ---- residue b23 ----\n",
    "final_predicted_b2 = residue_final.residue_inference( \\\n",
    "    test_images[1:-3], predicted_b2_frame, b, testing_ratio, \"residue_b23\")\n",
    "\n",
    "n_predicted2, amse2, apsnr2, assim2 = performance_evaluation(test_images[1:-3], final_predicted_b2, 0, 4)\n",
    "print(\"vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\")\n",
    "print('n_b2:',n_predicted2)\n",
    "print('average test b2_amse:',amse2)\n",
    "print('average test b2_apsnr:',apsnr2)\n",
    "print('average test b2_assim:',assim2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
