{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Disable INFO and WARNING messages from TensorFlow\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import numpy as np\n",
    "from imp import reload\n",
    "from keras.layers import * # YL\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# ============== DL ===============================\n",
    "# Limit GPU memory(VRAM) usage in TensorFlow 2.0\n",
    "# https://github.com/tensorflow/tensorflow/issues/34355\n",
    "# https://medium.com/@starriet87/tensorflow-2-0-wanna-limit-gpu-memory-10ad474e2528\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# ---- Method 1 ----\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "# ============== DL ===============================\n",
    "from utility.helper import psnr, load_imgs, image_to_block, regroup, save_imgs, performance_evaluation\n",
    "from utility.parameter import *\n",
    "\n",
    "import coarse.train as coarse_train\n",
    "import coarse.test as coarse_test\n",
    "import prediction.b1_train as prediction_train_b1\n",
    "import prediction.b1_inference as prediction_inference_b1\n",
    "import prediction.b23_train as prediction_train_b23\n",
    "import prediction.b23_inference as prediction_inference_b23\n",
    "import residue.b1_train as residue_train_b1\n",
    "import residue.b23_train as residue_train_b23\n",
    "import residue.b_inference as residue_final\n",
    "\n",
    "# ============== DL ===============================\n",
    "# Default is 1e-7 which is too small for float16.  \n",
    "# Without adjusting the epsilon, we will get NaN predictions because of divide by zero problems\n",
    "import keras.backend as K\n",
    "if rtx_optimizer == True:\n",
    "    K.set_epsilon(1e-4) \n",
    "# =================================================\n",
    "\n",
    "b = 16 # blk_size\n",
    "bm = 8 # target block size to predict\n",
    "\n",
    "train_start, train_end = 0, 100\n",
    "train_images = load_imgs(data_dir, train_start, train_end) \n",
    "n_train_frames = train_end - train_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==== coarse train b1 ====\n",
    "# coarse_train.model(train_images, b, training_ratio)\n",
    "\n",
    "# ==== prediction train b1 ====\n",
    "# decoded = coarse_test.predict(train_images, b, training_ratio)\n",
    "# prediction_train_b1.pred_train(train_images, decoded, b, bm, training_ratio)\n",
    "\n",
    "# ==== residue train b1 ====\n",
    "# predicted_b1_frame = prediction_inference_b1.pred_inference_b1(decoded, b, bm, training_ratio)\n",
    "# residue_train_b1.residue_train(train_images[2:n_train_frames - 2], predicted_b1_frame, bm, b, training_ratio)\n",
    "\n",
    "# ==== prediction train b23 ====\n",
    "# final_predicted_b1 = residue_final.residue_inference(train_images[2:n_train_frames-2], predicted_b1_frame, b, \"residue_b1\", training_ratio)\n",
    "# prediction_train_b23.pred_train_b23(decoded, final_predicted_b1, train_images, b, bm, training_ratio)\n",
    "\n",
    "# ==== residue train b23 ====\n",
    "# predicted_b2_frame = prediction_inference_b23.pred_inference_b23( \\\n",
    "#         decoded[0:n_train_frames - 4], final_predicted_b1, b, bm, training_ratio)\n",
    "# residue_train_b23.residue_train(train_images[1:n_train_frames - 3], predicted_b2_frame, bm, b, training_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from C:/Users/danni/Documents/GitHub/SPIEcode-Daniel/models/BlowingBubbles_416x240_50/48/hdf5/coarse.hdf5\n"
     ]
    }
   ],
   "source": [
    "# ---- coarse ----\n",
    "test_images = load_imgs(data_dir, test_start, test_end)\n",
    "decoded = coarse_test.predict(test_images, b, testing_ratio)\n",
    "\n",
    "# n2_evaluated, coarse_amse, coarse_apsnr, coarse_assim = performance_evaluation(test_images, decoded, 0, 1)\n",
    "# print('n_evaluated:',n2_evaluated)\n",
    "# print('average test coarse_amse:',coarse_amse)\n",
    "# print('average test coarse_apsnr:',coarse_apsnr)\n",
    "# print('average test coarse_assim:',coarse_assim)\n",
    "\n",
    "# save_imgs(save_dir, test_start, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from C:/Users/danni/Documents/GitHub/SPIEcode-Daniel/models/BlowingBubbles_416x240_50/48/hdf5/prediction.hdf5\n"
     ]
    }
   ],
   "source": [
    "# ---- prediction b1 ----\n",
    "predicted_b1_frame = prediction_inference_b1.pred_inference_b1(decoded, b, bm, testing_ratio)\n",
    "\n",
    "# n_predicted1, amse1, apsnr1, assim1 = performance_evaluation(test_images[2:n_test_frames-2], predicted_b1_frame, 0, 4)\n",
    "# print(\"vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\")\n",
    "# print('n_b1:',n_predicted1)\n",
    "# print('average test b1_amse:',amse1)\n",
    "# print('average test b1_apsnr:',apsnr1)\n",
    "# print('average test b1_assim:',assim1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from C:/Users/danni/Documents/GitHub/SPIEcode-Daniel/models/BlowingBubbles_416x240_50/48/hdf5/residue_b1.hdf5\n"
     ]
    }
   ],
   "source": [
    "# ---- residue b1 ----\n",
    "final_predicted_b1 = residue_final.residue_inference( \\\n",
    "    test_images[2:n_test_frames-2], predicted_b1_frame, b, \"residue_b1\", testing_ratio)\n",
    "\n",
    "# n_predicted1, amse1, apsnr1, assim1 = performance_evaluation(test_images[2:n_test_frames-2], final_predicted_b1, 0, 4)\n",
    "# print(\"vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\")\n",
    "# print('n_b1:',n_predicted1)\n",
    "# print('average test b1_amse:',amse1)\n",
    "# print('average test b1_apsnr:',apsnr1)\n",
    "# print('average test b1_assim:',assim1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from C:/Users/danni/Documents/GitHub/SPIEcode-Daniel/models/BlowingBubbles_416x240_50/48/hdf5/prediction_b23.hdf5\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "n_b2: 24\n",
      "average test b2_amse: 472.2774942539896\n",
      "average test b2_apsnr: 21.447607183732174\n",
      "average test b2_assim: 0.30975099200321193\n"
     ]
    }
   ],
   "source": [
    "# ---- prediction b23 ----\n",
    "predicted_b2_frame = prediction_inference_b23.pred_inference_b23( \\\n",
    "    decoded[0:n_test_frames - 4], final_predicted_b1, b, bm, testing_ratio)\n",
    "\n",
    "n_predicted2, amse2, apsnr2, assim2 = performance_evaluation(test_images[1:n_test_frames-3], predicted_b2_frame, 0, 4)\n",
    "print(\"vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\")\n",
    "print('n_b2:',n_predicted2)\n",
    "print('average test b2_amse:',amse2)\n",
    "print('average test b2_apsnr:',apsnr2)\n",
    "print('average test b2_assim:',assim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from C:/Users/danni/Documents/GitHub/SPIEcode-Daniel/models/BlowingBubbles_416x240_50/48/hdf5/residue_b23.hdf5\n",
      "vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "n_b2: 24\n",
      "average test b2_amse: 409.81514407151775\n",
      "average test b2_apsnr: 22.05997948331459\n",
      "average test b2_assim: 0.37553588640742913\n"
     ]
    }
   ],
   "source": [
    "# ---- residue b23 ----\n",
    "final_predicted_b2 = residue_final.residue_inference( \\\n",
    "    test_images[1:n_test_frames-3], predicted_b2_frame, b, \"residue_b23\", testing_ratio)\n",
    "\n",
    "n_predicted2, amse2, apsnr2, assim2 = performance_evaluation(test_images[1:n_test_frames-3], final_predicted_b2, 0, 4)\n",
    "print(\"vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\")\n",
    "print('n_b2:',n_predicted2)\n",
    "print('average test b2_amse:',amse2)\n",
    "print('average test b2_apsnr:',apsnr2)\n",
    "print('average test b2_assim:',assim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('average test overall_amse:', (pred_res_amse+coarse_amse)/2.0)\n",
    "# print('average test overall_apsnr:', (pred_res_apsnr+coarse_apsnr)/2.0)\n",
    "# print('average test overall_assim:', (pred_res_assim+coarse_assim)/2.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
